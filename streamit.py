# Streamlit App: Advanced ANN Classification - Breast Cancer# ============================================================import streamlit as stimport numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as snsfrom sklearn.datasets import load_breast_cancerfrom sklearn.model_selection import StratifiedShuffleSplitfrom sklearn.preprocessing import StandardScalerfrom sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matriximport tensorflow as tffrom tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import Dense, Dropoutfrom tensorflow.keras.regularizers import l2# -------------------------# APP TITLE# -------------------------st.title("Advanced ANN Classification - Breast Cancer Dataset")st.write("This app builds and evaluates an Artificial Neural Network to classify breast cancer tumors.")# -------------------------# LOAD DATA# -------------------------data = load_breast_cancer()X = data.datay = data.targetdf = pd.DataFrame(X, columns=data.feature_names)df['target'] = yst.subheader("Dataset Preview")st.write(df.head())st.subheader("Dataset Statistics")st.write(df.describe())st.subheader("Class Distribution")st.bar_chart(df['target'].value_counts())# -------------------------# PREPROCESSING# -------------------------scaler = StandardScaler()X_scaled = scaler.fit_transform(X)sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)for train_index, test_index in sss.split(X_scaled, y):    X_train, X_test = X_scaled[train_index], X_scaled[test_index]    y_train, y_test = y[train_index], y[test_index]# -------------------------# MODEL BUILDING# -------------------------st.subheader("ANN Model Summary")model = Sequential()model.add(Dense(32, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.001)))model.add(Dropout(0.3))model.add(Dense(16, activation='relu', kernel_regularizer=l2(0.001)))model.add(Dropout(0.3))model.add(Dense(1, activation='sigmoid'))model.compile(    loss='binary_crossentropy',    optimizer='adam',    metrics=['accuracy', tf.keras.metrics.Precision(name="precision")])model.summary(print_fn=lambda x: st.text(x))# -------------------------# TRAIN MODEL# -------------------------st.subheader("Train the Model")epochs = st.slider("Select Number of Epochs", 10, 100, 20, step=10)if st.button("Train Model"):    history = model.fit(        X_train, y_train,        validation_split=0.2,        epochs=epochs,        batch_size=32,        verbose=0    )    st.success("Model Trained Successfully!")    # -------------------------    # EVALUATION    # -------------------------    y_pred_prob = model.predict(X_test)    y_pred = (y_pred_prob >= 0.5).astype(int)    test_accuracy = accuracy_score(y_test, y_pred)    test_precision = precision_score(y_test, y_pred)    test_recall = recall_score(y_test, y_pred)    st.subheader("Test Metrics")    st.write(f"Accuracy: {test_accuracy:.4f}")    st.write(f"Precision: {test_precision:.4f}")    st.write(f"Recall: {test_recall:.4f}")    # Confusion Matrix    cm = confusion_matrix(y_test, y_pred)    st.subheader("Confusion Matrix")    fig, ax = plt.subplots()    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)    ax.set_xlabel("Predicted")    ax.set_ylabel("Actual")    st.pyplot(fig)    # Training Curves    st.subheader("Training Curves")    fig2, ax2 = plt.subplots(1,2, figsize=(12,4))    # Loss    ax2[0].plot(history.history['loss'], label='Training Loss')    ax2[0].plot(history.history['val_loss'], label='Validation Loss')    ax2[0].set_title("Loss Curve")    ax2[0].set_xlabel("Epochs")    ax2[0].set_ylabel("Loss")    ax2[0].legend()    # Accuracy    ax2[1].plot(history.history['accuracy'], label='Training Accuracy')    ax2[1].plot(history.history['val_accuracy'], label='Validation Accuracy')    ax2[1].set_title("Accuracy Curve")    ax2[1].set_xlabel("Epochs")    ax2[1].set_ylabel("Accuracy")    ax2[1].legend()    st.pyplot(fig2)    # Correct vs Incorrect Predictions    st.subheader("Correct vs Incorrect Predictions")    correct = np.sum(y_test == y_pred.flatten())    incorrect = np.sum(y_test != y_pred.flatten())    fig3, ax3 = plt.subplots()    ax3.bar(["Correct", "Incorrect"], [correct, incorrect], color=["green", "red"])    ax3.set_ylabel("Number of Samples")    ax3.set_title("Prediction Summary")    st.pyplot(fig3)    # Model Behavior Analysis    st.subheader("Model Behavior")    train_acc = history.history['accuracy'][-1]    val_acc = history.history['val_accuracy'][-1]    if abs(train_acc - val_acc) > 0.15:        st.write("⚠️ Model is **OVERFITTING**")    elif train_acc < 0.80:        st.write("⚠️ Model is **UNDERFITTING**")    else:        st.write("✅ Model is performing WELL")
0 commit comments